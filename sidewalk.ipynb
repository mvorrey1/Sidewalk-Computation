{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyproj.transformer import Transformer\n",
    "from shapely.geometry import asLineString\n",
    "import numpy as np\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union, LineString\n",
    "from sklearn.cluster import DBSCAN\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "import pptk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidarData = pd.read_csv(\"HD_Run1(0).csv\")\n",
    "lidarGDF = gpd.GeoDataFrame(data=lidarData, crs=4326, geometry=gpd.points_from_xy(lidarData[\"X\"], lidarData[\"Y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsData = pd.read_csv(\"gps.csv\")\n",
    "gpsGDF = gpd.GeoDataFrame(data=gpsData,crs=4326, geometry=gpd.points_from_xy(gpsData[\"X\"], gpsData[\"Y\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidarGDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsNP = gpsGDF.filter(['X','Y'])\n",
    "#gpsNP = gpsData.to_numpy()\n",
    "gpsNP = gpsNP.to_numpy()\n",
    "gpsNP\n",
    "# projectionTrans = Transformer.from_crs(4326, 'ESRI:102604', always_xy=True)\n",
    "# projPoints = np.array(projectionTrans.transform(point_list[:,0], point_list[:, 1], direction=\"forward\")).T\n",
    "# projPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPSline = asLineString(gpsNP)\n",
    "GPSline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN\n",
    "\n",
    "lidarNP = lidarData.filter(['X','Y'])\n",
    "lidarNP = lidarNP.to_numpy()\n",
    "lidarLine = asLineString(lidarNP)\n",
    "\n",
    "lidarLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 5m buffer around the GPS tragetory, and a list of all the LiDAR points within that buffer\n",
    "\n",
    "pointsWithinBuffer = lidarGDF.sindex.query(GPSline.buffer(5), predicate=\"contains\")\n",
    "print(pointsWithinBuffer.shape)\n",
    "\n",
    "pointsWithinBuffer = np.asarray(pointsWithinBuffer)\n",
    "offsetFilteredDf = lidarData.loc[pointsWithinBuffer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elevation Filtering\n",
    "\n",
    "for pt in gpsNP:\n",
    "    sampleBuffer = Point(pt[0], pt[1]).buffer(0.5)\n",
    "    pointsWithinBuffer = lidarGDF.sindex.query(sampleBuffer, predicate=\"contains\")\n",
    "\n",
    "    if len(pointsWithinBuffer) > 0:\n",
    "        median_elevation = statistics.median(lidarData.loc[np.asarray(pointsWithinBuffer)]['Z'])\n",
    "        offsetFilteredDf = offsetFilteredDf[(offsetFilteredDf['X'] > pt[0] + 5) | (offsetFilteredDf['X'] < pt[0] - 5)  | (offsetFilteredDf['Y'] > pt[1] + 5) | (offsetFilteredDf['Y'] < pt[1] - 5) | (offsetFilteredDf['Z'] < median_elevation + 0.4)]\n",
    "\n",
    "        \n",
    "print(offsetFilteredDf.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARTITION GPS LINE\n",
    "\n",
    "slice_frequency = 0.01\n",
    "slice_depth = 0.1\n",
    "whole_line = False\n",
    "\n",
    "# Chose a range on the line. 2000-2200 works well\n",
    "range_start = 2043\n",
    "range_end = 2046\n",
    "sample_starts = np.arange(range_start, range_end, slice_frequency)\n",
    "\n",
    "if whole_line:\n",
    "    sample_starts = np.arange(0, GPSline.length, slice_frequency)\n",
    "\n",
    "start_points = [GPSline.interpolate(distance) for distance in sample_starts] + [GPSline.boundary.geoms[1]]\n",
    "start_points = unary_union(start_points)\n",
    "print(len(start_points.geoms))\n",
    "start_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE SLICES OF ROAD, BASED ON DIST\n",
    "\n",
    "slices = []\n",
    "\n",
    "for dist in sample_starts:\n",
    "#for g in range(0, 150):\n",
    "    #dist = sample_starts[g]\n",
    "\n",
    "    sample_start = GPSline.interpolate(dist)\n",
    "    sample_end = GPSline.interpolate(dist + slice_depth)\n",
    "    sample_buffer = LineString([sample_start, sample_end]).buffer(5, cap_style=2)\n",
    "    offset_line = LineString([sample_buffer.exterior.coords[3], sample_buffer.exterior.coords[4]])\n",
    "    \n",
    "    sample_df = lidarData.loc[np.asarray(lidarGDF.sindex.query(sample_buffer, predicate=\"contains\"))]\n",
    "    points_in_sample = []\n",
    "    for i in sample_df['Id']:\n",
    "        points_in_sample.append((i, sample_df.loc[i]['geometry']))\n",
    "    \n",
    "\n",
    "    points_in_sample = sorted(points_in_sample, key=lambda x: x[1].distance(offset_line))\n",
    "\n",
    "    slice = []\n",
    "    for pt in points_in_sample:\n",
    "        slice.append((pt[1].distance(offset_line), sample_df.loc[pt[0]]['Z'], sample_df.loc[pt[0]]['geometry']))\n",
    "    slices.append(slice)\n",
    "\n",
    "    # Each \"slice\" in slices is a tuple of (dist_from_offset, z, POINT())\n",
    "    # Slices are sorted by their distance from the offset line\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDGE CREATION BASED ON DERIVATIVE\n",
    "\n",
    "edges = []\n",
    "h = 5\n",
    "mg = 0.01 # minimum gradient\n",
    "ma = 0.09 # minimum acceleration\n",
    "\n",
    "for slice in slices:\n",
    "    values = []\n",
    "    for i in range((len(slice) - (len(slice) % h)) // 2, len(slice) - (len(slice) % h), h):\n",
    "        pt = (statistics.mean([x[0] for x in slice[i:i+h]]), statistics.mean([x[1] for x in slice[i:i+h]]))\n",
    "        ## Check last and sign, add if sign changes\n",
    "        if len(values) < 5:\n",
    "            values.append(pt[1])\n",
    "        else:\n",
    "            values = values[1:]\n",
    "            values.append(pt[1])\n",
    "            if (values[0] > values[1]+mg and values[1] > values[2]+mg and values[3] > values[2]+mg and values[4] > values[3]+mg):\n",
    "                edges.append(Point(slice[i][2].x, slice[i][2].y, slice[i][1])) \n",
    "            elif (values[0]+mg < values[1] and values[1]+mg < values[2] and values[3]+mg < values[2] and values[4]+mg < values[3]):\n",
    "                edges.append(Point(slice[i][2].x, slice[i][2].y, slice[i][1]))\n",
    "            elif abs((values[4] - values[3]) - (values[3] - values[2])) > ma:\n",
    "                edges.append(Point(slice[i][2].x, slice[i][2].y, slice[i][1]))\n",
    "\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_plot_x = []\n",
    "edge_plot_y = []\n",
    "for pt in edges:\n",
    "    edge_plot_x.append(pt.x)\n",
    "    edge_plot_y.append(pt.y)\n",
    "\n",
    "plt.scatter(edge_plot_x, edge_plot_y, marker='.', alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_eplsilon = 0.085\n",
    "dbscan_min_samples = 2\n",
    "\n",
    "X = np.vstack((np.array(edge_plot_x), np.array(edge_plot_y))).T\n",
    "clustering = DBSCAN(eps=dbscan_eplsilon, min_samples=dbscan_min_samples).fit(X)\n",
    "\n",
    "\n",
    "color_labels = [\"lime\", \"r\", \"g\", \"b\", \"m\", \"c\", \"y\", \"k\", \"blueviolet\", \"tomato\", \"gold\", \"darkblue\", \"lime\", \"wheat\", \"teal\"]\n",
    "clustering.labels_\n",
    "\n",
    "clustered_x = []\n",
    "clustered_y = []\n",
    "cluster_colors = []\n",
    "for i in range(len(edges)):\n",
    "    if clustering.labels_[i] != -1:\n",
    "        clustered_x.append(edges[i].x)\n",
    "        clustered_y.append(edges[i].y)\n",
    "        cluster_colors.append(color_labels[clustering.labels_[i]])\n",
    "\n",
    "plt.scatter(clustered_x, clustered_y, marker='.', alpha=1, c=cluster_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renders The filtered points in 3D, and their retroflectivity\n",
    "\n",
    "filtered_xyz = offsetFilteredDf.filter(['X', 'Y', 'Z'])\n",
    "filtered_intensity = offsetFilteredDf.filter(['Retro'])\n",
    "\n",
    "filtered_intensity = np.array(filtered_intensity.Retro).transpose()\n",
    "print(filtered_intensity.shape)\n",
    "\n",
    "V = pptk.viewer(filtered_xyz)\n",
    "V.attributes(filtered_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "\n",
    "offsetFilteredDf.to_csv(\"filtered_points.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pptk_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34209c54219b5aa5600079aab92ac000e85b7fe219463d967adbbf84210a61f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
